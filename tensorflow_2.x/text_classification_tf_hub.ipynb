{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "devices = tf.config.list_physical_devices(\"GPU\")\n",
    "print(devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(devices[0], True)\n",
    "except:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the IMDB dataset\n",
    "\n",
    "- `tensorflow-dataset`에서 'imdb reviews' 데이터세트를 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name='imdb_reviews',\n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=string, numpy=\n",
       "array([b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\",\n",
       "       b'I have been known to fall asleep during films, but this is usually due to a combination of things including, really tired, being warm and comfortable on the sette and having just eaten a lot. However on this occasion I fell asleep because the film was rubbish. The plot development was constant. Constantly slow and boring. Things seemed to happen, but with no explanation of what was causing them or why. I admit, I may have missed part of the film, but i watched the majority of it and everything just seemed to happen of its own accord without any real concern for anything else. I cant recommend this film at all.',\n",
       "       b'Mann photographs the Alberta Rocky Mountains in a superb fashion, and Jimmy Stewart and Walter Brennan give enjoyable performances as they always seem to do. <br /><br />But come on Hollywood - a Mountie telling the people of Dawson City, Yukon to elect themselves a marshal (yes a marshal!) and to enforce the law themselves, then gunfighters battling it out on the streets for control of the town? <br /><br />Nothing even remotely resembling that happened on the Canadian side of the border during the Klondike gold rush. Mr. Mann and company appear to have mistaken Dawson City for Deadwood, the Canadian North for the American Wild West.<br /><br />Canadian viewers be prepared for a Reefer Madness type of enjoyable howl with this ludicrous plot, or, to shake your head in disgust.'],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_example_batch, train_label_batch = next(iter(train_data.batch(3)))\n",
    "train_example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=int64, numpy=array([0, 0, 0], dtype=int64)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "신경망은 레이어를 쌓음으로써 생성된다. 이 레이어를 쌓는 데에는 3 가지의 주요 아키텍처 결정이 필요하다.\n",
    "- **텍스트를 표현하는 방법은?**\n",
    "- **모델에 몇 층의 레이어를 쌓을 것인가?**\n",
    "- **각 레이어에 사용할 은닉 유닛은 몇 개인가?**\n",
    "\n",
    "이 연습에서는 입력데이터는 문장으로 구성된다. 또한 예측할 레이블은 0 또는 1 이다.\n",
    "\n",
    "텍스트를 표현하는 한 가지 방법은 문장을 임베딩 벡터로 변환하는 것이다. 사전 훈련된 텍스트 임베딩을 첫 번째 레이어로 사용하면 3 가지 이점이 있다.\n",
    "- 텍스트 전처리에 대해 걱정할 필요가 없다.\n",
    "- 전이 학습의 혜택\n",
    "- 임베딩은 크기가 고정되어 있어서 처리가 더 간단하다.\n",
    "\n",
    "*더 큰 차원의 임베딩은 성능을 향상시킬 수 있지만, 모델을 학습시키는 데 더 오래 걸릴 수 있다.*<br>\n",
    "*텍스트 정규화는 텍스트에 추가 문자나 구두점이 포함된 경우 도움이 될 수 있다.*<br>\n",
    "\n",
    "**입력 텍스트의 길이에 관계없이 임베딩의 출력 모양은 `(num_examples, embedding_dimention)` 이다.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 50), dtype=float32, numpy=\n",
       "array([[ 0.5423195 , -0.0119017 ,  0.06337538,  0.06862972, -0.16776837,\n",
       "        -0.10581174,  0.16865303, -0.04998824, -0.31148055,  0.07910346,\n",
       "         0.15442263,  0.01488662,  0.03930153,  0.19772711, -0.12215476,\n",
       "        -0.04120981, -0.2704109 , -0.21922152,  0.26517662, -0.80739075,\n",
       "         0.25833532, -0.3100421 ,  0.28683215,  0.1943387 , -0.29036492,\n",
       "         0.03862849, -0.7844411 , -0.0479324 ,  0.4110299 , -0.36388892,\n",
       "        -0.58034706,  0.30269456,  0.3630897 , -0.15227164, -0.44391504,\n",
       "         0.19462997,  0.19528408,  0.05666234,  0.2890704 , -0.28468323,\n",
       "        -0.00531206,  0.0571938 , -0.3201318 , -0.04418665, -0.08550783,\n",
       "        -0.55847436, -0.23336391, -0.20782952, -0.03543064, -0.17533456]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = 'https://tfhub.dev/google/nnlm-en-dim50/2'\n",
    "hub_layer = hub.KerasLayer(\n",
    "    embedding,\n",
    "    input_shape=[],\n",
    "    dtype=tf.string,\n",
    "    trainable=True\n",
    "    )\n",
    "hub_layer(train_example_batch[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " keras_layer_1 (KerasLayer)  (None, 50)                48190600  \n",
      "                                                                 \n",
      " dense (Dense)               (None, 16)                816       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 48,191,433\n",
      "Trainable params: 48,191,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 6s 109ms/step - loss: 0.6595 - accuracy: 0.5311 - val_loss: 0.6009 - val_accuracy: 0.6076\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 3s 97ms/step - loss: 0.5259 - accuracy: 0.7024 - val_loss: 0.4799 - val_accuracy: 0.7601\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 3s 92ms/step - loss: 0.3860 - accuracy: 0.8299 - val_loss: 0.3864 - val_accuracy: 0.8273\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 3s 96ms/step - loss: 0.2791 - accuracy: 0.8936 - val_loss: 0.3421 - val_accuracy: 0.8564\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 3s 94ms/step - loss: 0.2043 - accuracy: 0.9301 - val_loss: 0.3177 - val_accuracy: 0.8643\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 3s 91ms/step - loss: 0.1490 - accuracy: 0.9546 - val_loss: 0.3086 - val_accuracy: 0.8639\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 3s 100ms/step - loss: 0.1081 - accuracy: 0.9699 - val_loss: 0.3107 - val_accuracy: 0.8706\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 3s 105ms/step - loss: 0.0758 - accuracy: 0.9824 - val_loss: 0.3185 - val_accuracy: 0.8679\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 3s 95ms/step - loss: 0.0529 - accuracy: 0.9905 - val_loss: 0.3310 - val_accuracy: 0.8701\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 3s 99ms/step - loss: 0.0378 - accuracy: 0.9947 - val_loss: 0.3445 - val_accuracy: 0.8691\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data.shuffle(10000).batch(512),\n",
    "    epochs=10,\n",
    "    validation_data=validation_data.batch(512),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/49 - 2s - loss: 0.3706 - accuracy: 0.8535 - 2s/epoch - 37ms/step\n"
     ]
    }
   ],
   "source": [
    "result = model.evaluate(test_data.batch(512), verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.371\n",
      "accuracy: 0.854\n"
     ]
    }
   ],
   "source": [
    "for name, value in zip(model.metrics_names, result):\n",
    "    print(\"%s: %.3f\" % (name, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12fc454dd157f24b2200d9556262df19b2143ca898258cb04f885b2c2681ebac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

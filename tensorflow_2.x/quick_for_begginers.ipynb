{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 2.9.1\n",
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Tensorflow version:\", tf.__version__)\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(physical_devices)\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0 # 이미지 정규화하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build a machine learning model\n",
    "\n",
    "- 레이어를 쌓아 `tf.keras.Sequential` 모델 빌드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델은 각 이미지에 대해서 각 클래스에 대한 'logit' 또는 'log-odds'의 벡터를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.9337505 , -0.19494703, -0.29569054,  0.08765808, -0.10929985,\n",
       "        -0.3521268 ,  0.3264414 ,  0.51487756, -0.11004432,  0.529458  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `tf.nn.softmax`는 위의 로짓을 각 클래스에 대한 확률로 변환\n",
    "\n",
    "*'softmax' 함수를 네트워크의 마지막 레이어에 직접 입력하는 것이 가능하다. 이렇게 하면 모델 출력을 보다 직접적으로 해석할 수 있지만, 모든 모델에 대해 정확하고 수치적으로 안정적인 loss 계산을 제공하지 못하므로 권장하지 않는다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0381461 , 0.07985615, 0.07220313, 0.10593566, 0.08699704,\n",
       "        0.06824111, 0.13450687, 0.1623982 , 0.08693229, 0.1647834 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습을 위한 손실 함수 정의.\n",
    "- `loss.SparseCategoricalCrossentropy`: 이 함수는 logit 벡터와 True 인덱스를 사용하고, 각 이미지에 대한 스칼라 loss를 반환\n",
    "\n",
    "반환되는 loss는 실제 클래스의 음의 로그 확률과 같다. : 모델이 올바른 클래스를 확신하는 경우, loss는 0 이다.\n",
    "\n",
    "*이 튜토리얼에서 다루는 mnist의 경우, 아직 학습되지 않은 모델은 무작위에 가까운 확률(각 클래스에 대해 1/10 (0~9까지 10개의 클래스))을 제공하므로 초기 loss는 `tf.math.log(1/10) ~= 2.3`에 가까워야 한다.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.684708"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 학습을 시작하기 전에, Keras의 `Model.compile`을 사용하여 모델을 구성하고 컴파일 해야한다.\n",
    "    - `optimizer`를 설정한다.\n",
    "    - `loss function`을 설정한다.\n",
    "    - `metric`을 설정하여 모델에 대해 평가할 기준을 지정한다. (여기서는 'accuracy':정확도)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = loss_fn,\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate model\n",
    "\n",
    "- `model.fit`을 사용하여 model의 파라미터를 조정하고 loss를 최소화한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2944 - accuracy: 0.9165\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1415 - accuracy: 0.9582\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1084 - accuracy: 0.9669\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0888 - accuracy: 0.9729\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0767 - accuracy: 0.9757\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0659 - accuracy: 0.9791\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0580 - accuracy: 0.9815\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0527 - accuracy: 0.9829\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 9s 5ms/step - loss: 0.0478 - accuracy: 0.9842\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0445 - accuracy: 0.9855\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x29784074fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `model.evaluate`을 사용하여 'validation-set' 또는 'test-set'을 통해 모델의 성능을 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 - 1s - loss: 0.0732 - accuracy: 0.9784 - 1s/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0732107013463974, 0.9783999919891357]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 모델이 각 클래스에 대한 확률을 반화하도록 하려면 학습된 모델에 'softmax'를 추가하면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "    model,\n",
    "    tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 10), dtype=float32, numpy=\n",
       "array([[2.77213665e-08, 2.70608687e-12, 8.38690966e-08, 5.65931305e-06,\n",
       "        4.49088839e-14, 1.37167717e-07, 6.96044113e-18, 9.99990106e-01,\n",
       "        1.15460042e-08, 4.04251568e-06],\n",
       "       [1.01713427e-09, 6.75293677e-07, 9.99999285e-01, 2.04290274e-08,\n",
       "        6.12091035e-20, 1.05369324e-10, 3.88459737e-10, 3.12349454e-17,\n",
       "        5.34557953e-09, 1.97002899e-19],\n",
       "       [2.85876145e-09, 9.99682426e-01, 1.76210233e-05, 2.65339452e-07,\n",
       "        1.36495669e-06, 2.91723268e-08, 3.25693873e-06, 2.52197147e-04,\n",
       "        4.29370375e-05, 1.36576768e-08],\n",
       "       [9.99863267e-01, 3.85019843e-14, 1.11315174e-04, 1.29480576e-11,\n",
       "        2.23080558e-08, 2.58178012e-08, 2.51346773e-05, 7.41386188e-08,\n",
       "        7.95115571e-11, 8.85083580e-08],\n",
       "       [1.75259322e-06, 7.01340353e-13, 6.13977818e-07, 2.86237894e-10,\n",
       "        9.98783410e-01, 2.19724452e-08, 2.33533157e-07, 2.88961073e-05,\n",
       "        1.62124479e-07, 1.18489226e-03]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probability_model(x_test[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "12fc454dd157f24b2200d9556262df19b2143ca898258cb04f885b2c2681ebac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
